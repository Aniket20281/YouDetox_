{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:02.928797Z",
     "start_time": "2022-12-03T19:51:54.551078Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:06.480860Z",
     "start_time": "2022-12-03T19:52:06.406774Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('YT_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:07.541797Z",
     "start_time": "2022-12-03T19:52:07.467544Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:08.609495Z",
     "start_time": "2022-12-03T19:52:08.588094Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop('IsHomophobic',axis = 1,inplace = True)\n",
    "data.drop('IsRadicalism',axis = 1,inplace = True)\n",
    "data.drop('CommentId',axis = 1,inplace = True)\n",
    "data.drop('VideoId',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:09.599473Z",
     "start_time": "2022-12-03T19:52:09.570896Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:14.723543Z",
     "start_time": "2022-12-03T19:52:14.496986Z"
    }
   },
   "outputs": [],
   "source": [
    "## USING REGEX REMOVE STOPWORDS\n",
    "## CURRENTLY REMOVING STOPWORDS THROUGH NLTK\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def stopword_removal(txt):\n",
    "    stpwrds = re.compile(r'\\b(' + r'|'.join(stop_words) + r')\\b') \n",
    "    txt = stpwrds.sub('', txt)\n",
    "    li = list(txt.split(\" \"))\n",
    "    return li\n",
    "    #\\s*\n",
    "\n",
    "data[\"STOP\"] = data[\"Text\"].apply(lambda x:stopword_removal(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:16.481518Z",
     "start_time": "2022-12-03T19:52:16.369356Z"
    }
   },
   "outputs": [],
   "source": [
    "nostop = []\n",
    "for i in range(len(data)):\n",
    "    nostop.append(' '.join(data[\"STOP\"][i]))\n",
    "data[\"NOSTOP\"] = nostop\n",
    "data.drop(['STOP'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:24.495499Z",
     "start_time": "2022-12-03T19:52:19.745536Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "C. LEMMATIZATION\n",
    "importing WordNetLemmatizer from NLTK\n",
    "'''\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(txt):\n",
    "    lemm = [lemmatizer.lemmatize(word) for word in word_tokenize(txt)]\n",
    "    return lemm\n",
    "\n",
    "data[\"lemm\"] = data[\"NOSTOP\"].apply(lambda x:lemmatize(x))\n",
    "lemma = []\n",
    "for i in range(len(data)):\n",
    "    lemma.append(' '.join(data[\"lemm\"][i]))\n",
    "data[\"LEMM\"] = lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:24.572405Z",
     "start_time": "2022-12-03T19:52:24.500453Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:56:29.285998Z",
     "start_time": "2022-12-03T19:56:29.254656Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(columns = [\"Text\" , \"STOP\" , \"NOSTOP\" , \"lemm\"] , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:56:42.714349Z",
     "start_time": "2022-12-03T19:56:42.687098Z"
    }
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:57:47.572204Z",
     "start_time": "2022-12-03T19:57:47.526311Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('out.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:27.653005Z",
     "start_time": "2022-12-03T19:52:27.631108Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = data['IsToxic']\n",
    "X = data['LEMM']\n",
    "X_train_bow, X_test_bow, Y_train , Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:52:31.083706Z",
     "start_time": "2022-12-03T19:52:30.977138Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train_bow)\n",
    "X_train_bow = vectorizer.transform(X_train_bow)\n",
    "X_test_bow = vectorizer.transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLYING SOME WELL KNOWN CLASSIFIER ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticClassifier(X_train,Y_train,X_test,Y_test):\n",
    "#     clf = LogisticRegression()\n",
    "#     clf.fit(X_train,Y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     return accuracy_score(y_pred,Y_test)\n",
    "\n",
    "    solvers = ['lbfgs' , 'liblinear' , 'newton-cg','sag','saga']\n",
    "    penalty = ['l1', 'l2','elasticnet', 'none']\n",
    "    max_iter = [100, 1000,2500, 5000]\n",
    "    c_values = [0.01 , 0.1 , 0.45 , 0.5  , 0.65 , 1 , 1.5 , 10 , 100 , 1000]\n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    params_grid = {'solver' : solvers , 'penalty' : penalty , 'C' : c_values , 'max_iter' : max_iter}\n",
    "\n",
    "    gS = GridSearchCV(clf , param_grid = params_grid , scoring = 'accuracy', n_jobs = -1)\n",
    "    gS_ = gS.fit(X_train,Y_train)\n",
    "    y_pred = gS_.predict(X_test)\n",
    "    accuracy_score(y_pred , Y_test)\n",
    "    \n",
    "    \n",
    "def MultinomialNaiveClassifier(X_train,Y_train,X_test,Y_test):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_pred,Y_test)\n",
    "\n",
    "\n",
    "def GaussianNaiveClassifier(X_train,Y_train,X_test,Y_test):\n",
    "#     clf = GaussianNB()\n",
    "#     clf.fit(X_train,Y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     return accuracy_score(y_pred,Y_test)\n",
    "\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=999)\n",
    "\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "    clf_gnb = GaussianNB()\n",
    "\n",
    "    gs_NB = GridSearchCV(estimator=clf_gnb, param_grid=params_NB, cv=cv_method, verbose=1, scoring='accuracy')\n",
    "\n",
    "    # Data_transformed = PowerTransformer().fit_transform(X_temp)\n",
    "    \n",
    "#     X_train = X_train.toarray()\n",
    "#     Y_train = Y_train.to_numpy()\n",
    "#     X_test = X_test.toarray()\n",
    "#     Y_test = Y_test.to_numpy()\n",
    "    \n",
    "    gs_NB.fit(X_train , Y_train)\n",
    "    \n",
    "    predict_test = gs_NB.predict(X_test)\n",
    "\n",
    "    # Accuracy Score on test dataset\n",
    "    accuracy_test = accuracy_score(Y_test,predict_test)\n",
    "    return accuracy_test\n",
    "\n",
    "def DecisionTree(X_train,Y_train,X_test,Y_test):\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    parameter_dict = {\n",
    "        \"criterion\":[\"gini\",\"entropy\"],\n",
    "        \"max_depth\":[5,6,7,8,9,10,11,12],\n",
    "        \"min_samples_split\":[2,3,4,5],\n",
    "        \"min_samples_leaf\":[1,2,3,4,5]\n",
    "    }\n",
    "    grid = GridSearchCV(clf,param_grid=parameter_dict,cv=10,verbose=1,n_jobs=1)\n",
    "    grid.fit(X_train,Y_train)\n",
    "    \n",
    "    y_pred = grid.predict(X_test)\n",
    "    return accuracy_score(y_pred, Y_test)\n",
    "\n",
    "def RandomForest(X_train,Y_train,X_test,Y_test):\n",
    "#     clf = RandomForestClassifier(max_depth=10,random_state=0)\n",
    "#     clf.fit(X_train,Y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     return accuracy_score(y_pred,Y_test)\n",
    "    random_grid = {'bootstrap': [True, False],\n",
    "               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000] }\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    rf_random.fit(X_train,Y_train)\n",
    "    \n",
    "    y_pred = rf_random.predict(X_test)\n",
    "    return accuracy_score(y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:07.095812Z",
     "start_time": "2022-10-30T15:17:07.078737Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:09.571960Z",
     "start_time": "2022-10-30T15:17:09.545950Z"
    }
   },
   "outputs": [],
   "source": [
    "X_temp = X_train_bow.toarray()\n",
    "Y_temp = Y_train.to_numpy()\n",
    "X_temp_test = X_test_bow.toarray()\n",
    "Y_temp_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:32:29.889685Z",
     "start_time": "2022-10-29T18:32:29.829676Z"
    }
   },
   "outputs": [],
   "source": [
    "## LOGISTIC REGRESSION\n",
    "## 0.652\n",
    "## 0.732 (simple)\n",
    "## 0.692 (count vectorizer)\n",
    "## 0.732 (first stopword removal then lemmatize then countvectorize)\n",
    "accuracy_logistic = LogisticClassifier(X_train_bow,Y_train,X_test_bow,Y_test)\n",
    "print(accuracy_logistic)\n",
    "accuracies.append(accuracy_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPROVING LR-MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:36:06.544476Z",
     "start_time": "2022-10-29T18:36:06.539493Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:41:25.928053Z",
     "start_time": "2022-10-29T18:36:06.999794Z"
    }
   },
   "outputs": [],
   "source": [
    "solvers = ['lbfgs' , 'liblinear' , 'newton-cg','sag','saga']\n",
    "penalty = ['l1', 'l2','elasticnet', 'none']\n",
    "max_iter = [100, 1000,2500, 5000]\n",
    "c_values = [0.01 , 0.1 , 0.45 , 0.5  , 0.65 , 1 , 1.5 , 10 , 100 , 1000]\n",
    "clf = LogisticRegression()\n",
    "\n",
    "params_grid = {'solver' : solvers , 'penalty' : penalty , 'C' : c_values , 'max_iter' : max_iter}\n",
    "\n",
    "gS = GridSearchCV(clf , param_grid = params_grid , scoring = 'accuracy', n_jobs = -1)\n",
    "gS_ = gS.fit(X_train_bow,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:41:41.282726Z",
     "start_time": "2022-10-29T18:41:41.275451Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = gS_.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:41:42.607542Z",
     "start_time": "2022-10-29T18:41:42.601553Z"
    }
   },
   "outputs": [],
   "source": [
    "gS_.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:41:45.244371Z",
     "start_time": "2022-10-29T18:41:45.229362Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_pred , Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:44:20.904643Z",
     "start_time": "2022-10-29T18:44:20.826645Z"
    }
   },
   "outputs": [],
   "source": [
    "## Decision tree classifier\n",
    "## 0.64\n",
    "## 0.632 (simple)\n",
    "## 0.664 (cv)\n",
    "accuracy_dt = DecisionTree(X_train_bow,Y_train,X_test_bow,Y_test)\n",
    "print(accuracy_dt)\n",
    "accuracies.append(accuracy_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:44:24.395290Z",
     "start_time": "2022-10-29T18:44:24.192658Z"
    }
   },
   "outputs": [],
   "source": [
    "## random forest classifier\n",
    "## 0.636\n",
    "## 0.656 (simple)\n",
    "## 0.62 (cv)\n",
    "accuracy_random_forest = RandomForest(X_train_bow,Y_train,X_test_bow,Y_test)\n",
    "print(accuracy_random_forest)\n",
    "accuracies.append(accuracy_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:44:27.202820Z",
     "start_time": "2022-10-29T18:44:27.097066Z"
    }
   },
   "outputs": [],
   "source": [
    "## gaussian naive classifier\n",
    "## 0.552 (preprocessed own)\n",
    "## 0.54 (simple)\n",
    "## 0.52\n",
    "accuracy_gaussian = GaussianNaiveClassifier(X_temp,Y_temp,X_temp_test,Y_temp_test)\n",
    "print(accuracy_gaussian)\n",
    "accuracies.append(accuracy_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:44:29.030502Z",
     "start_time": "2022-10-29T18:44:28.970669Z"
    }
   },
   "outputs": [],
   "source": [
    "## multinomial naive classifier\n",
    "## 0.624\n",
    "## 0.676 (simple)\n",
    "accuracy_multinomial = MultinomialNaiveClassifier(X_temp,Y_temp,X_temp_test,Y_temp_test)\n",
    "print(accuracy_multinomial)\n",
    "accuracies.append(accuracy_multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_tfidf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:45:29.319838Z",
     "start_time": "2022-10-29T18:45:29.244512Z"
    }
   },
   "outputs": [],
   "source": [
    "## changes to be done from here\n",
    "## ----------------------------------\n",
    "Y_tf = data['IsToxic']\n",
    "X_tf = data['LEMM']\n",
    "\n",
    "X_train_tf,X_test_tf,Y_train_tf,Y_test_tf = train_test_split(X_tf,Y_tf,random_state = 1)\n",
    "\n",
    "vectorizer_tf = TfidfVectorizer(lowercase=True,stop_words='english')\n",
    "vectorizer_tf.fit(X_train_tf)\n",
    "X_train_tf = vectorizer.transform(X_train_tf)\n",
    "X_test_tf = vectorizer.transform(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:45:29.753934Z",
     "start_time": "2022-10-29T18:45:29.732183Z"
    }
   },
   "outputs": [],
   "source": [
    "X_temp_tf = X_train_tf.toarray()\n",
    "Y_temp_tf = Y_train_tf.to_numpy()\n",
    "X_temp_test_tf = X_test_tf.toarray()\n",
    "Y_temp_test_tf = Y_test_tf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T18:45:30.456394Z",
     "start_time": "2022-10-29T18:45:30.241049Z"
    }
   },
   "outputs": [],
   "source": [
    "## logistic classifier tf-idf\n",
    "## 0.668 (pre)\n",
    "## 0.732 (simple)\n",
    "## 0.692 (tf)\n",
    "## 0.696 (stopword->lemmatize->tf-idf)\n",
    "accuracy_logistic_tf = LogisticClassifier(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "print(accuracy_logistic_tf)\n",
    "accuracies_tfidf.append(accuracy_logistic_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:15:06.807791Z",
     "start_time": "2022-10-29T18:46:13.533971Z"
    }
   },
   "outputs": [],
   "source": [
    "solvers = ['lbfgs' , 'liblinear' , 'newton-cg','sag','saga']\n",
    "penalty = ['l1', 'l2','elasticnet', 'none']\n",
    "max_iter = [100, 1000,2500, 5000]\n",
    "c_values = [0.01 , 0.1 , 0.45 , 0.5  , 0.65 , 1 , 1.5 , 10 , 100 , 1000]\n",
    "clf = LogisticRegression()\n",
    "\n",
    "params_grid = {'solver' : solvers , 'penalty' : penalty , 'C' : c_values , 'max_iter' : max_iter}\n",
    "\n",
    "gS = GridSearchCV(clf , param_grid = params_grid , scoring = 'accuracy', n_jobs = -1)\n",
    "gS_ = gS.fit(X_temp_tf,Y_temp_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random forest classifier tf-idf\n",
    "## 0.628 (tf)\n",
    "## 0.648 (stopword->lemmatize->tf-idf)\n",
    "accuracy_random_forest_tf = RandomForest(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "print(accuracy_random_forest_tf)\n",
    "accuracies_tfidf.append(accuracy_random_forest_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision tree classifier tf-idf\n",
    "## 0.664 (tf)\n",
    "## 0.672 (stopword->lemmatize->tf-idf)\n",
    "accuracy_dt_tf = DecisionTree(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "print(accuracy_dt_tf)\n",
    "accuracies_tfidf.append(accuracy_dt_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gaussian naive classifier tf-idf\n",
    "## 0.52(tf)\n",
    "## 0.532 (stopword->lemmatize->tf-idf)\n",
    "accuracy_gaussian_tf = GaussianNaiveClassifier(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "print(accuracy_gaussian_tf)\n",
    "accuracies_tfidf.append(accuracy_gaussian_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## multinomial naive classifier tf-idf\n",
    "## 0.676 (simple)\n",
    "## 0.676 (tf)\n",
    "## 0.664 (stopword->lemmatize->tf-idf)\n",
    "accuracy_multinomial_tf = MultinomialNaiveClassifier(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "print(accuracy_multinomial_tf)\n",
    "accuracies_tfidf.append(accuracy_multinomial_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:23.250270Z",
     "start_time": "2022-10-30T15:17:23.235236Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = data.select_dtypes(include= [\"bool\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:39:08.171005Z",
     "start_time": "2022-10-31T00:39:08.161008Z"
    }
   },
   "outputs": [],
   "source": [
    "data_bow = []\n",
    "data_tfidf = []\n",
    "columns = ['Label'   , 'Logistic Regression' , 'Decision Tree' , 'Random Forest' , 'Gaussian NB' , 'Multinomial NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:39:29.054139Z",
     "start_time": "2022-10-31T00:39:08.667477Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(classes)):\n",
    "    \n",
    "    # BOW \n",
    "    accuracies = [classes[i]]\n",
    "    Y = data[classes[i]]\n",
    "    X = data['LEMM']\n",
    "    X_train_bow, X_test_bow, Y_train , Y_test = train_test_split(X,Y)\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(X_train_bow)\n",
    "    X_train_bow = vectorizer.transform(X_train_bow)\n",
    "    X_test_bow = vectorizer.transform(X_test_bow)\n",
    "    \n",
    "    X_temp = X_train_bow.toarray()\n",
    "    Y_temp = Y_train.to_numpy()\n",
    "    X_temp_test = X_test_bow.toarray()\n",
    "    Y_temp_test = Y_test.to_numpy()\n",
    "    \n",
    "    ## logistic Regression\n",
    "    accuracy_logistic = LogisticClassifier(X_train_bow,Y_train,X_test_bow,Y_test)\n",
    "    accuracies.append(accuracy_logistic)\n",
    "    \n",
    "    ## Decision Tree\n",
    "    accuracy_dt = DecisionTree(X_train_bow,Y_train,X_test_bow,Y_test)\n",
    "    accuracies.append(accuracy_dt)\n",
    "    \n",
    "    ## Random Forest\n",
    "    accuracy_random_forest = RandomForest(X_train_bow,Y_train,X_test_bow,Y_test)\n",
    "    accuracies.append(accuracy_random_forest)\n",
    "    \n",
    "    ## Gaussian NB\n",
    "    accuracy_gaussian = GaussianNaiveClassifier(X_temp,Y_temp,X_temp_test,Y_temp_test)\n",
    "    accuracies.append(accuracy_gaussian)\n",
    "    \n",
    "    ## Multinomial NB\n",
    "    accuracy_multinomial = MultinomialNaiveClassifier(X_temp,Y_temp,X_temp_test,Y_temp_test)\n",
    "    accuracies.append(accuracy_multinomial)\n",
    "    \n",
    "    \n",
    "    # TF-IDF\n",
    "    accuracies_tfidf = [classes[i]]\n",
    "    \n",
    "    Y_tf = data[classes[i]]\n",
    "    X_tf = data['LEMM']\n",
    "\n",
    "    X_train_tf,X_test_tf,Y_train_tf,Y_test_tf = train_test_split(X_tf,Y_tf,random_state = 1)\n",
    "\n",
    "    vectorizer_tf = TfidfVectorizer(lowercase=True,stop_words='english')\n",
    "    vectorizer_tf.fit(X_train_tf)\n",
    "    X_train_tf = vectorizer.transform(X_train_tf)\n",
    "    X_test_tf = vectorizer.transform(X_test_tf)\n",
    "    \n",
    "    X_temp_tf = X_train_tf.toarray()\n",
    "    Y_temp_tf = Y_train_tf.to_numpy()\n",
    "    X_temp_test_tf = X_test_tf.toarray()\n",
    "    Y_temp_test_tf = Y_test_tf.to_numpy()\n",
    "    \n",
    "    ## logistic Regression\n",
    "    accuracy_logistic_tf = LogisticClassifier(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "    accuracies_tfidf.append(accuracy_logistic_tf)\n",
    "    \n",
    "    ## Decision Tree\n",
    "    accuracy_dt_tf = DecisionTree(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "    accuracies_tfidf.append(accuracy_dt_tf)\n",
    "    \n",
    "    ## Random Forest\n",
    "    accuracy_random_forest_tf = RandomForest(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "    accuracies_tfidf.append(accuracy_random_forest_tf)\n",
    "    \n",
    "    ## Gaussian NB\n",
    "    accuracy_gaussian_tf = GaussianNaiveClassifier(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "    accuracies_tfidf.append(accuracy_gaussian_tf)\n",
    "    \n",
    "    ## Multinomial NB\n",
    "    accuracy_multinomial_tf = MultinomialNaiveClassifier(X_temp_tf,Y_temp_tf,X_temp_test_tf,Y_temp_test_tf)\n",
    "    accuracies_tfidf.append(accuracy_multinomial_tf)\n",
    "    \n",
    "    \n",
    "    data_bow.append(accuracies)\n",
    "    data_tfidf.append(accuracies_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:39:31.343703Z",
     "start_time": "2022-10-31T00:39:31.334700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:39:47.265234Z",
     "start_time": "2022-10-31T00:39:47.253216Z"
    }
   },
   "outputs": [],
   "source": [
    "data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:40:46.795103Z",
     "start_time": "2022-10-31T00:40:46.765115Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bow = pd.DataFrame(data_bow , columns= columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:40:47.039008Z",
     "start_time": "2022-10-31T00:40:47.023278Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(data_tfidf , columns= columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:40:47.645737Z",
     "start_time": "2022-10-31T00:40:47.621738Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T00:40:48.250318Z",
     "start_time": "2022-10-31T00:40:48.236107Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:58:17.035252Z",
     "start_time": "2022-12-03T19:58:17.010716Z"
    }
   },
   "outputs": [],
   "source": [
    "check = pd.read_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:58:19.174067Z",
     "start_time": "2022-12-03T19:58:19.122651Z"
    }
   },
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
